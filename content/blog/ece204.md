+++
title="Annotated ECE204"
date=2024-02-08
+++

# Approximating integrals

There are three main methods:

1. **Midpoint rule**: estimate definite integral using _piecewise constant functions_.
2. **Trapezoidal rule**: estimate using _piecewise linear functions_.
3. **Simpson's rule**: estimate using _piecewise quadratic functions_.

## Trapezoid rule

{% definition(ref="Trapezoid rule") %}
Approximates the definite integral.

Given a function $f(x)$, we take a selection of points.
We then connect them into a set of trapezoids and calculate the area.

$$\int_a^b f(x)\, dx \approx (b-a)\frac{1}2(f(a)+f(b))$$

Given equal spacing of the points $$\Delta x$$ from $x_0$ to $x_{N-1}$, this becomes[^1]

$$\int_a^b f(x)\, dx \approx \frac{\Delta x}2 \sum^N_{k=1} (f(x_{k-1}) + f(x_k))$$
{% end %}

Comparisons can be drawn between this and Riemann summing.

## Centered $O(h^5)$ backwards approximation

We may integrate the interpolating polynomial on the points

- $(t_{k-3}, f(t_{k-3}))$
- $(t_{k-2}, f(t_{k-2}))$
- $(t_{k-1}, f(t_{k-1}))$
- $(t_k, f(t_k))$

For each $k$.
The interpolating polynomial will 

## Simpson's rule

{% definition(ref="Simpson's rule") %}
Approximate the function $f$ using piecewise quadratic functions.

- Partition the interval into even number of subintervals with same length.
- Over the first pair of subintervals approximate $\int_{x_0}^{x_2} f(x)\, dx$ with $\int_{x_0}^{x_2} p(x)\, dx$, where $p(x) = Ax^2 + Bx^2 + C$ is the interpolating polynomial passing through

- $(x_0, f(x_0))$
- $(x_1, f(x_1))$
- $(x_2, f(x_2))$

{% end %}

{% theorem(ref="Simpson's rule") %}
Assume that $f(x)$ is continuous over $I = [a, b]$. Let $n$ be a positive even integer and $\Delta x = \frac{b-a}n$. Let $I$ be divided into $n$ subintervals, each of length $\Delta x$, with endpoints at $P=\{x_0, x_1, x_2, \ldots, x_n \}$. Set

$$S_n = \frac{\Delta x}{3} \left [ f(x_0) + 4f(x_1) + 2 f(x_2) + \ldots + 2f(x_{n-2}) + 4f(x_{n-1}) + f(x_n) \right ]$$


Then:

$$\lim_{n\to +\infty} S_n = \int_a^b f(x)\, dx$$
{% end %}

The **error bound** for the statement above approximating $f(x)$ can be given as:

If $M$ is the maximum value of $\lvert f^{(4)}(x)\rvert$ over $I$, then the upper bound for the actual error $\delta$ in using $S_n$ to estimate $\int_a^bf(x)\, dx$ is given by

$$\delta \le \frac{M(b-a)^5}{180 n^4}$$


# Least-squares best-fitting polynomials

Suppose that we are given a linear system that is overdetermined.
There is no linear combination of the columns of $A$ that equals the target vetor.

What linear combination is _closest_ to $\vec v$?

Let $A: \mathcal{U}\mapsto \mathcal{V}$ be a linear map, usually from $\mathbb{R}^n\mapsto \mathbb{R}^m$

We want to minimize the norm:

$$\lvert\lvert \mathbb{A} \vec u - \vec v\rvert \rvert_{2}$$

and find a $\vec u$ that makes it as small as possible.

The object is to find $\vec u_0$ such that $\mathbb{A}u_0 - v$ is perpendicular to all vectors in range of $\mathbb{A}\vec u$

We derive that

$$u_0 = (\mathbb{A}^T\mathbb{A})^{-1} \mathbb{A}^T \vec v$$

$$A^T A \vec u_0 = A^T v$$

Is the vector that minimizes the norm.

* * *

[^1]: Wikipedia Contributors, _Trapezoidal rule_, Accessed 2024.

[^2]: LibreTexts Mathematics, _7.7: Approximate Integration_, Accessed 2024.

[^3]: Douglas Wilhelm Harder, _In a nutshell: Least-squares best-fitting polynomial_, <https://ece.uwaterloo.ca/~dwharder/nm/Lecture_materials/pdfs/5.3%20Least-squares%20best-fitting%20polynomials%20in%20a%20nutshell.pdf>
